## Notes for lish-moa kaggle exercise
##### Notes from intial conversation with Dotun
CS, Wall St, Seattle Metis summer 2019
Thinking about doing a PhD
Github repo
- Check correlation matrices
- Logistic regression with LASSO
- PCA reduction of feature dimensions
- Deep learning

Dotun can set up GitHub
I can set up basic notebooks, data visualization
PCA -> logistic regression with...
2 weeks / rest of October
Blog posts & reporting
Twice a week Mon 5 pm & Thurs 4 pm Eastern
Lasso / PCA, Lasso / ensemble, logistic / ensemble
    use for Dask, Spark, Google Colab

- Do some research on setting up NN projects
	- Start with Metis repo, 1-2 other sources
- Hammer out a loose strategy for EDA and basic classifier results

##### Thoughts as of Monday Oct 12
Thoughts are all over the place, as per usual since Metis ended and definitely the past month. We identified an MVP: do PCA and then a logistic regression on each target individually. That's simple enough. All sorts of other tricks we could do after that, in many categories. I can't possibly 

###### Take home from today's conversation
I will look at correlation coefficients & PCA, possible need for standard scaling on the features. Hopefully do a first cut on a k-fold eval on either logistic regression or naive Bayes just one target column.
